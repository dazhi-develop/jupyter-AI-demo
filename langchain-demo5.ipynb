{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "memory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回message格式\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"what's up?\")\n",
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "\n",
    "history.add_ai_message(\"whats up?\")\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "# Notice that \"chat_history\" is present in the prompt template\n",
    "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human question: {question}\n",
    "Response:\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "memory.chat_memory.add_user_message(\"你是谁!\")\n",
    "memory.chat_memory.add_ai_message(\"我是一个诗人\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "conversation({\"question\": \"你是诗人吗\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'On sam: sam is a friend.'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "memory = ConversationKGMemory(llm=llm)\n",
    "memory.save_context({\"input\": \"say hi to sam\"}, {\"output\": \"who is sam\"})\n",
    "memory.save_context({\"input\": \"sam is a friend\"}, {\"output\": \"okay\"})\n",
    "memory.load_memory_variables({\"input\": \"who is sam\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在chain中使用kg\n",
    "from langchain.chains import ConversationChain\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)\n",
    "conversation_with_kg = ConversationChain(\n",
    "    llm=llm, verbose=True, prompt=prompt, memory=ConversationKGMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: Hi, what's up?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Hello! I am an AI programmed to assist with various tasks and provide information. Currently, I am running on a server with 64 GB of RAM and a 2.5 GHz processor. I am also connected to the internet with a speed of 100 Mbps. Is there something specific you would like to know?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.predict(input=\"Hi, what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "\n",
      "\n",
      "Conversation:\n",
      "Human: My name is James and I'm helping Will. He's an engineer.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hello James, it's nice to meet you. I am an AI designed to assist with various tasks. Will sounds like a very interesting person. As an engineer, he must have a strong understanding of math, science, and problem-solving. Is there anything specific you need help with?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.predict(\n",
    "    input=\"My name is James and I'm helping Will. He's an engineer.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
      "\n",
      "Relevant Information:\n",
      "\n",
      "On Will: Will is an engineer.\n",
      "\n",
      "Conversation:\n",
      "Human: What do you know about Will?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Will is an engineer. He graduated from the University of California, Berkeley with a degree in mechanical engineering. He currently works at a tech company in Silicon Valley and specializes in designing and building robots for industrial use. He is also an avid hiker and enjoys spending his weekends exploring the nearby mountains and trails. Is there anything specific you would like to know about Will?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_kg.predict(input=\"What do you know about Will?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('James', 'Will', 'is helping'), ('Will', 'engineer', 'is an'), ('Will', 'tech company', 'works at'), ('Will', 'designing and building robots', 'specializes in'), ('Will', 'hiker', 'is an avid'), ('Will', 'weekends exploring mountains and trails', 'enjoys spending')]\n"
     ]
    }
   ],
   "source": [
    "print(conversation_with_kg.memory.kg.get_triples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"\\nThe human greets the AI and asks what's up. The AI responds by asking what's going on.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "memory = ConversationSummaryMemory(llm=OpenAI(temperature=0))\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryMemory(llm=OpenAI()),\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/pytorch/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 我喜欢运动，所以我想买一个篮球\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '我喜欢运动，所以我想买一个篮球', 'history': '', 'response': ' 那你是一个运动爱好者啊！我也很喜欢运动，尤其是篮球。你想买什么样的篮球呢？有很多不同的品牌和款式，我可以帮你推荐一些。你喜欢什么样的颜色和材质？还有你的预算是多少？我可以帮你找到最适合你的篮球。'}\n"
     ]
    }
   ],
   "source": [
    "response = conversation_with_summary(\"我喜欢运动，所以我想买一个篮球\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human expresses their interest in sports and wanting to purchase a basketball. The AI responds by saying it is also a sports enthusiast and can help recommend different brands and styles based on the human's preferences and budget.\n",
      "Human: 我喜欢威尔逊品牌的\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '我喜欢威尔逊品牌的', 'history': \"\\nThe human expresses their interest in sports and wanting to purchase a basketball. The AI responds by saying it is also a sports enthusiast and can help recommend different brands and styles based on the human's preferences and budget.\", 'response': ' 威尔逊是一家非常知名的体育用品品牌，专门生产篮球、网球和高尔夫球等运动用具。它的篮球产品质量优良，深受运动员和球迷的喜爱。您可以选择威尔逊的室内篮球，它具有良好的弹性和控球性能，非常适合在室内场地使用。另外，威尔逊还有许多不同款式和价格的篮球可供选择，您可以根据自己的喜好和预算来挑选。'}\n"
     ]
    }
   ],
   "source": [
    "response = conversation_with_summary(\"我喜欢威尔逊品牌的\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human expresses their interest in sports and wanting to purchase a basketball. The AI responds by saying it is also a sports enthusiast and can help recommend different brands and styles based on the human's preferences and budget. The AI suggests the Wilson brand, known for its high-quality basketball products and popularity among athletes and fans. They recommend the indoor basketball for its good bounce and ball control, and mention that there are various styles and prices to choose from.\n",
      "Human: 我又来了，有什么篮球推荐吗\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '我又来了，有什么篮球推荐吗', 'history': \"\\nThe human expresses their interest in sports and wanting to purchase a basketball. The AI responds by saying it is also a sports enthusiast and can help recommend different brands and styles based on the human's preferences and budget. The AI suggests the Wilson brand, known for its high-quality basketball products and popularity among athletes and fans. They recommend the indoor basketball for its good bounce and ball control, and mention that there are various styles and prices to choose from.\", 'response': ' 当然，我也是一个运动爱好者，很乐意帮你推荐不同品牌和款式的篮球。我推荐Wilson品牌，它以高质量的篮球产品和受运动员和球迷欢迎而闻名。我建议选择室内篮球，因为它有良好的弹跳和球控制，而且有各种不同的款式和价格可供选择。'}\n"
     ]
    }
   ],
   "source": [
    "response = conversation_with_summary(\"我又来了，有什么篮球推荐吗\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
